{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARKIFY PROJECT - DATA UNDERSTANDING\n",
    "This notebook explores a tiny subset (128MB) of the full dataset available (12GB).  \n",
    "Both can be retrieved here:\n",
    "* 128MB subset: [s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json](s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json)\n",
    "* full 12GB dataset: [s3n://udacity-dsnd/sparkify/sparkify_event_data.json](s3n://udacity-dsnd/sparkify/sparkify_event_data.json)\n",
    "\n",
    "Goal of this notebook is to explore the dataset with few statistics in order to have a better understanding of the data we are dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, init Spark and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import desc, isnan, when, count, col\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is useful to know the version we are using when reading the pyspark documentations\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or retrieve a Spark session\n",
    "spark = SparkSession.builder.appName(\"dsnd-p7-sparkify\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+-----------------+------+-------------+--------------------+------+\n",
      "|          artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page| registration|sessionId|             song|status|           ts|           userAgent|userId|\n",
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+-----------------+------+-------------+--------------------+------+\n",
      "|  Martha Tilston|Logged In|    Colin|     M|           50| Freeman|277.89016| paid|     Bakersfield, CA|   PUT|NextSong|1538173362000|       29|        Rockpools|   200|1538352117000|Mozilla/5.0 (Wind...|    30|\n",
      "|Five Iron Frenzy|Logged In|    Micah|     M|           79|    Long|236.09424| free|Boston-Cambridge-...|   PUT|NextSong|1538331630000|        8|           Canada|   200|1538352180000|\"Mozilla/5.0 (Win...|     9|\n",
      "|    Adam Lambert|Logged In|    Colin|     M|           51| Freeman| 282.8273| paid|     Bakersfield, CA|   PUT|NextSong|1538173362000|       29|Time For Miracles|   200|1538352394000|Mozilla/5.0 (Wind...|    30|\n",
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+-----------------+------+-------------+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"mini_sparkify_event_data.json\")\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pyspark dataframe has shape (286500, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded pyspark dataframe has shape ({}, {})\".format(df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DATA UNDERSTANDING\n",
    "To get a better understanding of data we are dealing with and their type, let's first proceed with an analysis, feature per feature.  \n",
    "\n",
    "# 1. Dataset schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 18 features to analyze. Lets go!\n",
    "\n",
    "# 2. `Artist` feature\n",
    "It's pretty obvious that it relates to the artist the user is currently listening to. But are there empty rows? Depending on the event type that has been collected perhaps sometimes this value is empty and we are OK with that. Let's see.\n",
    "\n",
    "## 2.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            artist|\n",
      "+-------+------------------+\n",
      "|  count|            228108|\n",
      "|   mean| 551.0852017937219|\n",
      "| stddev|1217.7693079161374|\n",
      "|    min|               !!!|\n",
      "|    max| ÃÂlafur Arnalds|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('artist').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we have 228108 non null values, other statistics are not relevant as this is a categorical feature. `min` and `max` are related to alphabetical order.\n",
    "\n",
    "## 2.2. Number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17656"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['artist']).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we have only around 18K different artists. Let's see who is the favourite one!\n",
    "\n",
    "## 2.3. Which artist is the most represented in this subset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              artist|count|\n",
      "+--------------------+-----+\n",
      "|       Kings Of Leon| 1841|\n",
      "|            Coldplay| 1813|\n",
      "|Florence + The Ma...| 1236|\n",
      "|       Dwight Yoakam| 1135|\n",
      "|            BjÃÂ¶rk| 1133|\n",
      "|      The Black Keys| 1125|\n",
      "|                Muse| 1090|\n",
      "|       Justin Bieber| 1044|\n",
      "|        Jack Johnson| 1007|\n",
      "|              Eminem|  953|\n",
      "|           Radiohead|  884|\n",
      "|     Alliance Ethnik|  876|\n",
      "|               Train|  854|\n",
      "|        Taylor Swift|  840|\n",
      "|         OneRepublic|  828|\n",
      "|         The Killers|  822|\n",
      "|         Linkin Park|  787|\n",
      "|         Evanescence|  781|\n",
      "|            Harmonia|  729|\n",
      "|       Guns N' Roses|  713|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(['artist']).agg({'artist': 'count'}).withColumnRenamed(\"count(artist)\", \"count\").sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Missing value analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|artist|\n",
      "+------+\n",
      "| 58392|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Made with https://stackoverflow.com/questions/44627386/how-to-find-count-of-null-and-nan-values-for-each-column-in-a-pyspark-dataframe?rq=1\n",
    "df.select([count(when(isnan('artist') | col('artist').isNull(), 'artist')).alias('artist')]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expected to find ```286500 - 228108 = 58392```. That's good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When it is empty, what are the values for the feature `page`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                page|count|\n",
      "+--------------------+-----+\n",
      "|                Home|14457|\n",
      "|           Thumbs Up|12551|\n",
      "|     Add to Playlist| 6526|\n",
      "|          Add Friend| 4277|\n",
      "|         Roll Advert| 3933|\n",
      "|               Login| 3241|\n",
      "|              Logout| 3226|\n",
      "|         Thumbs Down| 2546|\n",
      "|           Downgrade| 2055|\n",
      "|                Help| 1726|\n",
      "|            Settings| 1514|\n",
      "|               About|  924|\n",
      "|             Upgrade|  499|\n",
      "|       Save Settings|  310|\n",
      "|               Error|  258|\n",
      "|      Submit Upgrade|  159|\n",
      "|    Submit Downgrade|   63|\n",
      "|              Cancel|   52|\n",
      "|Cancellation Conf...|   52|\n",
      "|            Register|   18|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(isnan('artist') | col('artist').isNull()).groupby('page').agg({'page': 'count'}).withColumnRenamed(\"count(page)\", \"count\").sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we have a lot of different values for the visited page when `artist` is empty but most of the time it happens when user is on homepage, interacting with its account (`Login`, `Logout`, `Settings`) or the \"Social part\" of the app (`Add Friend`, `Thumbs Up` or `Down`).\n",
    "\n",
    "# 3. `Auth` feature\n",
    "First, we build some functions that will help to analyze each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_stats(df, col_name):\n",
    "    \"\"\"\n",
    "    Show statistic for the given column name in the given dataset. If feature is numerical you can pay attention to mean and \n",
    "    standard deviation values but otherwise those are just fancy things that you should not pay attention to.\n",
    "    :param df: (pyspark DataFrame) the data to analyze\n",
    "    :param col_name: (string) the colum name\n",
    "    :return: feature statistics\n",
    "    \"\"\"\n",
    "    return df.describe(col_name).show()\n",
    "\n",
    "def value_counts(df, col_name):\n",
    "    \"\"\"\n",
    "    Display all possible values for a given column and the count for each value (similar to pandas value_counts() in the end)\n",
    "    :param df: (pyspark DataFrame) the data to analyze\n",
    "    :param col_name: (string) the colum name\n",
    "    :return: pyspark DataFrame with all possible values for a given column and the count for each value\n",
    "    \"\"\"\n",
    "    df.groupby([col_name]).agg({col_name: 'count'}).withColumnRenamed(\"count({})\".format(col_name), \"count\").sort(desc(\"count\")).show()\n",
    "\n",
    "def count_missing_values(df, col_name):\n",
    "    \"\"\"\n",
    "    Count how many missing values for the given column\n",
    "    :param df: (pyspark DataFrame) the data to analyze\n",
    "    :param col_name: (string) the colum name\n",
    "    :return: pyspark DataFrame with the count of missing values for the given column\n",
    "    \"\"\"\n",
    "    return df.select([count(when(isnan(col_name) | col(col_name).isNull(), col_name)).alias(col_name)]).show()\n",
    "\n",
    "def get_other_col_value_counts_when_col_is_null(df, null_col_name, other_col):\n",
    "    \"\"\"\n",
    "    Display the different values and their counts for the feature 'page' when there are many missing values for the given column\n",
    "    :param df: (pyspark DataFrame) the data to analyze\n",
    "    :param null_col_name: (string) the colum name with missing values\n",
    "    :param other_col: (string) the other colum name for which we will display all possible values\n",
    "    :return: pyspark DataFrame with the count of value counts for 'page' when there are missing values in the given column\n",
    "    \"\"\"\n",
    "    return value_counts(df.filter(isnan(null_col_name) | col(null_col_name).isNull()), other_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we have a lot of different values for the visited page when `artist` is empty but most of the time it happens when user is on homepage, interacting with its account (`Login`, `Logout`, `Settings`) or the \"Social part\" of the app (`Add Friend`, `Thumbs Up` or `Down`).\n",
    "\n",
    "# 3. `Auth` feature\n",
    "## 3.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|summary|      auth|\n",
      "+-------+----------+\n",
      "|  count|    286500|\n",
      "|   mean|      null|\n",
      "| stddev|      null|\n",
      "|    min| Cancelled|\n",
      "|    max|Logged Out|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'auth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we have no null values, other statistics are not relevant as this is a categorical feature. `min` and `max` are related to alphabetical order.\n",
    "\n",
    "## 3.2. Number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      auth| count|\n",
      "+----------+------+\n",
      "| Logged In|278102|\n",
      "|Logged Out|  8249|\n",
      "|     Guest|    97|\n",
      "| Cancelled|    52|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'auth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** it seems that this feature is related to user authentication: is the user authenticated or not. 97% of this feature has the value `Logged In` so I am not sure that it is relevant to keep it. We'll see.\n",
    "\n",
    "# 4. `firstName` and `lastName` features\n",
    "It's pretty obvious that it relates to the user itself. Same questions: are there empty rows? Let's see.\n",
    "\n",
    "## 4.1. Features statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|summary|firstName|\n",
      "+-------+---------+\n",
      "|  count|   278154|\n",
      "|   mean|     null|\n",
      "| stddev|     null|\n",
      "|    min| Adelaida|\n",
      "|    max|   Zyonna|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'firstName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|summary|firstName|\n",
      "+-------+---------+\n",
      "|  count|   278154|\n",
      "|   mean|     null|\n",
      "| stddev|     null|\n",
      "|    min| Adelaida|\n",
      "|    max|   Zyonna|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'firstName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we have few missing values, other statistics are not relevant as this is a categorical feature. `min` and `max` are related to alphabetical order.  \n",
    "We will not count the number of distinct values as it will not be meaningful, several users can have the same name.\n",
    "\n",
    "## 4.2. Missing values\n",
    "First let's build some functions that will be used to analyze missing values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|firstName|\n",
      "+---------+\n",
      "|     8346|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_missing_values(df, 'firstName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|lastName|\n",
      "+--------+\n",
      "|    8346|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_missing_values(df, 'lastName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When it is empty, what are the values for the feature `page`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|               page|count|\n",
      "+-------------------+-----+\n",
      "|               Home| 4375|\n",
      "|              Login| 3241|\n",
      "|              About|  429|\n",
      "|               Help|  272|\n",
      "|           Register|   18|\n",
      "|              Error|    6|\n",
      "|Submit Registration|    5|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_other_col_value_counts_when_col_is_null(df, 'firstName', 'page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|               page|count|\n",
      "+-------------------+-----+\n",
      "|               Home| 4375|\n",
      "|              Login| 3241|\n",
      "|              About|  429|\n",
      "|               Help|  272|\n",
      "|           Register|   18|\n",
      "|              Error|    6|\n",
      "|Submit Registration|    5|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_other_col_value_counts_when_col_is_null(df, 'lastName', 'page')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** \n",
    "* We have exactly the same figures for both `firstName` and `lastName` features, that's a good point!\n",
    "* `firstName` or `lastName` are empty where the page is `Home` or `Logged In`, it is obvious as at this time we do not know who is the visitor. Anyway, as it does not bring any information for our churn prediction problem, it is not relevant to keep those 2 features.\n",
    "\n",
    "# 5. `Gender` feature\n",
    "It should be related to the user's gender. Number of missing value should then be the same, more or less, than what we have seen earlier with `firstName`. Let's see.\n",
    "\n",
    "## 5.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|summary|gender|\n",
      "+-------+------+\n",
      "|  count|278154|\n",
      "|   mean|  null|\n",
      "| stddev|  null|\n",
      "|    min|     F|\n",
      "|    max|     M|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** as expected, we have the same number of missing values we have found when analyzing `firstName`.\n",
    "\n",
    "## 5.2. Most represented gender?\n",
    "We have to take care about user duplicates and must take distinct values. For that, instead of `firstName` I will use the `userId` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|     M|  121|\n",
      "|     F|  104|\n",
      "|  null|    0|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df.select('userId', 'gender').dropDuplicates(), 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check this information by counting the number of different userId\n",
    "df.select('userId').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humm, there is small a difference: 226 distinct user id whereas we found 225 when summing 'M' and 'F' genders.  \n",
    "Perhaps it is linked to an empty row, that would explain the \"null\" value we got in the gender count above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. `itemInSession` feature\n",
    "So far I am not sure what it means so let's analyze it in details.\n",
    "\n",
    "## 6.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|     itemInSession|\n",
      "+-------+------------------+\n",
      "|  count|            286500|\n",
      "|   mean|114.41421291448516|\n",
      "| stddev|129.76726201140994|\n",
      "|    min|                 0|\n",
      "|    max|              1321|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'itemInSession')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the feature name, I would say that it contains the number of elements played within a single session.  \n",
    "***Observations:***\n",
    "* We have no null values and the column is numerical so we can also have a look at other statistics such as the `mean` or the `standard deviation`.  \n",
    "* Note that we have a `min` at 0 and I my assumption is right so, we should have the same amount of '0' than missing values for `firstName`.  \n",
    "* There is not enough information so far to say whether the `max` value is an outlier or not. We'll see that later during the EDA phase (perhaps plotting a boxplot of that if it helps.\n",
    "\n",
    "## 6.2. Number of 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3278"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['itemInSession'] == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|firstname|\n",
      "+---------+\n",
      "|      589|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['itemInSession'] == 0).select([count(when(isnan('firstName') | col('firstName').isNull(), 'firstname')).alias('firstname')]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** no, it is not exact! Perhaps this would become clearer when doing some plots.\n",
    "\n",
    "# 7. `length` feature\n",
    "As for `itemInSession`, I am not sure what it means so let's analyze it in details.\n",
    "\n",
    "## 7.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|           length|\n",
      "+-------+-----------------+\n",
      "|  count|           228108|\n",
      "|   mean|249.1171819778458|\n",
      "| stddev|99.23517921058361|\n",
      "|    min|          0.78322|\n",
      "|    max|       3024.66567|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* 228108 is the same number we have found earlier and corresponds to the number of not null `Artist` feature so those 2 are obviously connected.\n",
    "* The column is numerical so it is interesting to have a look at statistics figures. Based on the values for the mean or even the max, I guess that this is the length of the song that has been played.\n",
    "\n",
    "## 7.2. Confirm it is the song's length\n",
    "For that I will take randomly few songs that appears more than once in the dataset. The length related to the song should always be the same. If it is not the case then it would mean something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                song|count|\n",
      "+--------------------+-----+\n",
      "|      You're The One| 1153|\n",
      "|                Undo| 1026|\n",
      "|             Revelry|  854|\n",
      "|       Sehr kosmisch|  728|\n",
      "|Horn Concerto No....|  641|\n",
      "|Dog Days Are Over...|  574|\n",
      "|             Secrets|  466|\n",
      "|        Use Somebody|  459|\n",
      "|              Canada|  435|\n",
      "|             Invalid|  424|\n",
      "|    Ain't Misbehavin|  409|\n",
      "|       ReprÃÂ©sente|  393|\n",
      "|SinceritÃÂ© Et J...|  384|\n",
      "|Catch You Baby (S...|  373|\n",
      "|              Yellow|  343|\n",
      "|    Somebody To Love|  343|\n",
      "|    Hey_ Soul Sister|  334|\n",
      "|            The Gift|  327|\n",
      "|           Fireflies|  312|\n",
      "|          Love Story|  309|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|            song|   length|\n",
      "+----------------+---------+\n",
      "|          Yellow|174.75873|\n",
      "|      Love Story|179.46077|\n",
      "|          Canada|413.28281|\n",
      "|       Fireflies|208.97914|\n",
      "|      Love Story|199.52281|\n",
      "|          Yellow|218.14812|\n",
      "|Somebody To Love|211.53914|\n",
      "|       Fireflies|195.02975|\n",
      "|          Canada|236.09424|\n",
      "|Somebody To Love|473.23383|\n",
      "|          Yellow|268.30322|\n",
      "|    Use Somebody|231.26159|\n",
      "|Somebody To Love|179.53914|\n",
      "|    Use Somebody|231.81016|\n",
      "|      Love Story|233.89995|\n",
      "|      Love Story|312.73751|\n",
      "|      Love Story|236.01587|\n",
      "|Somebody To Love|220.89098|\n",
      "|       Fireflies|225.17506|\n",
      "|      Love Story|245.36771|\n",
      "+----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_to_check = ['Use Somebody', 'Canada', 'Yellow', 'Love Story', 'Fireflies', 'Somebody To Love']\n",
    "df.filter(df['song'].isin(songs_to_check)).select('song', 'length').dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** we can see different values for the same song so this is not the length of the song that has been played but it could instead be the **listening duration for this song**.\n",
    "\n",
    "# 8. `level` feature\n",
    "Still no real clue about what it is so let's analyze it in details.\n",
    "\n",
    "## 8.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|summary| level|\n",
      "+-------+------+\n",
      "|  count|286500|\n",
      "|   mean|  null|\n",
      "| stddev|  null|\n",
      "|    min|  free|\n",
      "|    max|  paid|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* This is a categorical column and corresponds to the different levels of service the user has suscribed to.\n",
    "* There are not missing values (even for user without firstName? So then they are considered...what? Free?)\n",
    "\n",
    "## 8.2. How many different levels available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|level| count|\n",
      "+-----+------+\n",
      "| paid|228162|\n",
      "| free| 58338|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|level|count|\n",
      "+-----+-----+\n",
      "| paid| 5729|\n",
      "| free| 2617|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When first name is null, what are the possible values for 'level'?\n",
    "get_other_col_value_counts_when_col_is_null(df, 'firstName', 'level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|level|count|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strange, let's now try with 'userId':\n",
    "get_other_col_value_counts_when_col_is_null(df, 'userId', 'level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|      | 8346|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Okayyyy, when firstName is null, userId is not necessarily null, we have an empty string! That's why we found 8346\n",
    "# values for levels above\n",
    "get_other_col_value_counts_when_col_is_null(df, 'firstName', 'userId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. `location` feature\n",
    "With this name I guess that it is related to user's location, let's see if I am right.\n",
    "\n",
    "## 9.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|         location|\n",
      "+-------+-----------------+\n",
      "|  count|           278154|\n",
      "|   mean|             null|\n",
      "| stddev|             null|\n",
      "|    min|       Albany, OR|\n",
      "|    max|Winston-Salem, NC|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* This is a categorical column and corresponds to the different locations of users.\n",
    "* It seems that all users are from United States.\n",
    "* There are same amount of missing values as missing `firstName` and so on.\n",
    "* We could try to plot a map where users tend to churn more but for our prediction problem I thing I will not keep this feature.\n",
    "\n",
    "## 9.2. How many different locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            location|count|\n",
      "+--------------------+-----+\n",
      "|Los Angeles-Long ...|30131|\n",
      "|New York-Newark-J...|23684|\n",
      "|Boston-Cambridge-...|13873|\n",
      "|Houston-The Woodl...| 9499|\n",
      "|Charlotte-Concord...| 7780|\n",
      "|Dallas-Fort Worth...| 7605|\n",
      "|Louisville/Jeffer...| 6880|\n",
      "|Philadelphia-Camd...| 5890|\n",
      "|Chicago-Napervill...| 5114|\n",
      "|    St. Louis, MO-IL| 4858|\n",
      "|Phoenix-Mesa-Scot...| 4846|\n",
      "|Vineland-Bridgeto...| 4825|\n",
      "|          Wilson, NC| 4659|\n",
      "|Denver-Aurora-Lak...| 4453|\n",
      "|           Ionia, MI| 4428|\n",
      "|San Antonio-New B...| 4373|\n",
      "|        Danville, VA| 4257|\n",
      "|Atlanta-Sandy Spr...| 4236|\n",
      "|New Haven-Milford...| 4007|\n",
      "|         Jackson, MS| 3839|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** we have the confirmation that all the locations are actually different cities from United States.\n",
    "\n",
    "# 10. `method` feature\n",
    "No real clue about what it is so let's analyze it in details.\n",
    "\n",
    "## 10.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|summary|method|\n",
      "+-------+------+\n",
      "|  count|286500|\n",
      "|   mean|  null|\n",
      "| stddev|  null|\n",
      "|    min|   GET|\n",
      "|    max|   PUT|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* This is a categorical column\n",
    "* \"GET\" and \"PUT\" are HTTP methods, could it be possible that this feature relates to the HTTP method used for the user's action?\n",
    "* There are no missing values (which seems logic if my assumption is correct).\n",
    "\n",
    "## 10.2. How many different methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|method| count|\n",
      "+------+------+\n",
      "|   PUT|261064|\n",
      "|   GET| 25436|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** we have only 2 possible values so let's say I am right. Would have been better to see values such as \"POST\" but it does not matter because there are high chances that this feature will not be kept in the end.\n",
    "\n",
    "# 11. `page` feature\n",
    "As explained in project overview video, this is related to the user's action.\n",
    "\n",
    "## 11.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|summary|   page|\n",
      "+-------+-------+\n",
      "|  count| 286500|\n",
      "|   mean|   null|\n",
      "| stddev|   null|\n",
      "|    min|  About|\n",
      "|    max|Upgrade|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'page')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* This is a categorical column\n",
    "* There are no missing values\n",
    "\n",
    "## 11.2. How many different pages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                page| count|\n",
      "+--------------------+------+\n",
      "|            NextSong|228108|\n",
      "|                Home| 14457|\n",
      "|           Thumbs Up| 12551|\n",
      "|     Add to Playlist|  6526|\n",
      "|          Add Friend|  4277|\n",
      "|         Roll Advert|  3933|\n",
      "|               Login|  3241|\n",
      "|              Logout|  3226|\n",
      "|         Thumbs Down|  2546|\n",
      "|           Downgrade|  2055|\n",
      "|                Help|  1726|\n",
      "|            Settings|  1514|\n",
      "|               About|   924|\n",
      "|             Upgrade|   499|\n",
      "|       Save Settings|   310|\n",
      "|               Error|   258|\n",
      "|      Submit Upgrade|   159|\n",
      "|    Submit Downgrade|    63|\n",
      "|              Cancel|    52|\n",
      "|Cancellation Conf...|    52|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"page\").dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* We have 228108 values for 'NextSong', the same number than no missing values for `Artist`. This is far the most represented page in the dataset.\n",
    "* There are 22 different values possible but not all of them are displayed in the first table. Anyway, this is OK as the 20th has only 52 rows.\n",
    "\n",
    "In our churn prediction problem, we will classify as \"churned\" a user with `Cancellation Confirmation` page. It means that **in our dataset we have 52 users over the 225 who are churned ones (around 23%)**.\n",
    "\n",
    "# 12. `registration` feature\n",
    "The schema showed that this is numeric, let's see what it is exactly.\n",
    "\n",
    "## 12.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|        registration|\n",
      "+-------+--------------------+\n",
      "|  count|              278154|\n",
      "|   mean|1.535358834084427...|\n",
      "| stddev| 3.291321616327586E9|\n",
      "|    min|       1521380675000|\n",
      "|    max|       1543247354000|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'registration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* We have the same number of missing values than for `firstName` and so on so this feature is related to user.\n",
    "* Values seems to be timestamp so I guess with the column name that it relates to the date the user registered.\n",
    "\n",
    "## 12.2. Date range for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range is from 2018-03-18 13:44:35 to 2018-11-26 15:49:14\n"
     ]
    }
   ],
   "source": [
    "begin = datetime.fromtimestamp(df.agg({\"registration\": \"min\"}).collect()[0][0]/1000)\n",
    "end = datetime.fromtimestamp(df.agg({\"registration\": \"max\"}).collect()[0][0]/1000)\n",
    "print(\"Date range is from {} to {}\".format(begin, end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** we have users who registered within a 8 months period\n",
    "\n",
    "# 13. `sessionId` feature\n",
    "This should be a technical id for the user's session. Let's confirm that thought.\n",
    "\n",
    "## 13.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|        sessionId|\n",
      "+-------+-----------------+\n",
      "|  count|           286500|\n",
      "|   mean|1041.526554973822|\n",
      "| stddev|726.7762634630741|\n",
      "|    min|                1|\n",
      "|    max|             2474|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'sessionId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* We have no missing values.\n",
    "* `min` is 1 and `max` is another value, let's see if 2474 is the number of unique session, that would mean that each new session in the dataset is a counter incrementing by 1.\n",
    "\n",
    "## 13.2. How many unique values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2354"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('sessionId').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we have more or less the same number of sessions as the \"max\" value. This feature is probably not relevant for our churn prediction problem.\n",
    "\n",
    "# 14. `song` feature\n",
    "Self-explanatory, this is the song currently played by the user. And we should have the same number of missing values than with `Artist`.\n",
    "\n",
    "## 14.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|                song|\n",
      "+-------+--------------------+\n",
      "|  count|              228108|\n",
      "|   mean|            Infinity|\n",
      "| stddev|                 NaN|\n",
      "|    min|\u001c",
      "ÃÂg ÃÂtti Gr...|\n",
      "|    max|ÃÂau hafa slopp...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'song')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** we have same number of missing values, as expected.\n",
    "\n",
    "## 14.2. What is the most played song?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                song|count|\n",
      "+--------------------+-----+\n",
      "|      You're The One| 1153|\n",
      "|                Undo| 1026|\n",
      "|             Revelry|  854|\n",
      "|       Sehr kosmisch|  728|\n",
      "|Horn Concerto No....|  641|\n",
      "|Dog Days Are Over...|  574|\n",
      "|             Secrets|  466|\n",
      "|        Use Somebody|  459|\n",
      "|              Canada|  435|\n",
      "|             Invalid|  424|\n",
      "|    Ain't Misbehavin|  409|\n",
      "|       ReprÃÂ©sente|  393|\n",
      "|SinceritÃÂ© Et J...|  384|\n",
      "|Catch You Baby (S...|  373|\n",
      "|              Yellow|  343|\n",
      "|    Somebody To Love|  343|\n",
      "|    Hey_ Soul Sister|  334|\n",
      "|            The Gift|  327|\n",
      "|           Fireflies|  312|\n",
      "|          Love Story|  309|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'song')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. `status` feature\n",
    "This is ambiguous so let's analyze it.\n",
    "\n",
    "## 15.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            status|\n",
      "+-------+------------------+\n",
      "|  count|            286500|\n",
      "|   mean|210.05459685863875|\n",
      "| stddev| 31.50507848842214|\n",
      "|    min|               200|\n",
      "|    max|               404|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* We have no missing values.\n",
    "* `min` and `max` does not give so much information so far.\n",
    "\n",
    "## 15.2. How many unique values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|status| count|\n",
      "+------+------+\n",
      "|   200|259812|\n",
      "|   307| 26430|\n",
      "|   404|   258|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is related to HTTP code (remember that we also have HTTP method in the dataset so why not HTTP code...?). Here are the meanings:\n",
    "* 200: OK (request worked without error)\n",
    "* 404: page not found\n",
    "* 307: Temporary Redirect\n",
    "\n",
    "For more details, please refer to this [page](https://developer.mozilla.org/fr/docs/Web/HTTP/Status).\n",
    "\n",
    "# 16. `ts` feature\n",
    "\"ts\" is oftenly used as timestamp abbreviation\n",
    "\n",
    "## 16.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|                  ts|\n",
      "+-------+--------------------+\n",
      "|  count|              286500|\n",
      "|   mean|1.540956889810483...|\n",
      "| stddev|1.5075439608226302E9|\n",
      "|    min|       1538352117000|\n",
      "|    max|       1543799476000|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2. Date range for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range is from 2018-10-01 00:01:57 to 2018-12-03 01:11:16\n"
     ]
    }
   ],
   "source": [
    "begin = datetime.fromtimestamp(df.agg({\"ts\": \"min\"}).collect()[0][0]/1000)\n",
    "end = datetime.fromtimestamp(df.agg({\"ts\": \"max\"}).collect()[0][0]/1000)\n",
    "print(\"Date range is from {} to {}\".format(begin, end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** we have 2 months data (remember that we have users who registered within a 8 months period: from March to November)\n",
    "\n",
    "# 17. `userAgent` feature\n",
    "I guess this is the user-agent value for user's browser. More details about what is user agent [here].(https://en.wikipedia.org/wiki/User_agent).\n",
    "\n",
    "## 17.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|           userAgent|\n",
      "+-------+--------------------+\n",
      "|  count|              278154|\n",
      "|   mean|                null|\n",
      "| stddev|                null|\n",
      "|    min|\"Mozilla/5.0 (Mac...|\n",
      "|    max|Mozilla/5.0 (comp...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'userAgent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we have as many missing values as for features related to users (`firstName`, `lastName`, etc)\n",
    "\n",
    "## 17.2. How many unique values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('userAgent').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           userAgent|count|\n",
      "+--------------------+-----+\n",
      "|\"Mozilla/5.0 (Win...|22751|\n",
      "|\"Mozilla/5.0 (Mac...|19611|\n",
      "|\"Mozilla/5.0 (Mac...|18448|\n",
      "|\"Mozilla/5.0 (Mac...|17348|\n",
      "|Mozilla/5.0 (Wind...|16700|\n",
      "|\"Mozilla/5.0 (Win...|15395|\n",
      "|\"Mozilla/5.0 (Win...|14598|\n",
      "|Mozilla/5.0 (Maci...|10300|\n",
      "|\"Mozilla/5.0 (iPa...| 8912|\n",
      "|Mozilla/5.0 (comp...| 8624|\n",
      "|\"Mozilla/5.0 (Mac...| 8094|\n",
      "|\"Mozilla/5.0 (Win...| 7923|\n",
      "|\"Mozilla/5.0 (Mac...| 7906|\n",
      "|\"Mozilla/5.0 (Win...| 7624|\n",
      "|\"Mozilla/5.0 (iPh...| 6417|\n",
      "|Mozilla/5.0 (Wind...| 5989|\n",
      "|\"Mozilla/5.0 (Mac...| 5716|\n",
      "|\"Mozilla/5.0 (Win...| 5238|\n",
      "|\"Mozilla/5.0 (Win...| 4917|\n",
      "|Mozilla/5.0 (Wind...| 4663|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'userAgent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** it seems that we could be able to extract the user's OS (Windows, Mac) or device (iPad, iPhone). It might be used to analyze whether users from one or another OS tend to churn more than others (thus meaning perhaps that the app is not giving satisfaction or is buggy).\n",
    "\n",
    "# 18. `userId` feature\n",
    "Must be a technical id for the user. We have already seen many times that there are 8346 missing values for features related to users.\n",
    "\n",
    "## 18.1. Feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|           userId|\n",
      "+-------+-----------------+\n",
      "|  count|           286500|\n",
      "|   mean|59682.02278593872|\n",
      "| stddev|109091.9499991047|\n",
      "|    min|                 |\n",
      "|    max|               99|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_feature_stats(df, 'userId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:*** we can see here the empty string for the user id. At first glance, it seems there is no missing value but actually there are.\n",
    "\n",
    "## 17.2. How many unique values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|    39| 9632|\n",
      "|      | 8346|\n",
      "|    92| 7230|\n",
      "|   140| 6880|\n",
      "|300011| 5732|\n",
      "|   124| 4825|\n",
      "|300021| 4659|\n",
      "|300017| 4428|\n",
      "|    85| 4370|\n",
      "|    42| 4257|\n",
      "|200023| 3769|\n",
      "|     6| 3761|\n",
      "|    29| 3603|\n",
      "|    54| 3437|\n",
      "|   100| 3214|\n",
      "|     9| 3191|\n",
      "|   126| 3102|\n",
      "|300015| 3051|\n",
      "|    91| 3014|\n",
      "|    98| 2891|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts(df, 'userId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19. CONCLUSION\n",
    "Here is a summary of this first phase of Data Exploration:\n",
    "\n",
    "| Column name | Type | Data Definition | Decision |\n",
    "|-------------|-----------------|----------|----------|\n",
    "| `artist`    | Categorical     | Name of the artist the user is currently listening to | **Drop**, it will not help us to identify when user will churn |\n",
    "| `auth`    | Categorical     | Login status of the user | **Drop**, it will not help us to identify when user will churn |\n",
    "| `firstName`    | Categorical     | First name of the user | **Drop**, it will not help us to identify when user will churn |\n",
    "| `lastName`    | Categorical     | Last name of the user | **Drop**, it will not help us to identify when user will churn |\n",
    "| `gender`    | Categorical     | Gender of the user | **Drop**, it will not help us to identify when user will churn |\n",
    "| `itemInSession`    | Numerical     | Number of elements played in the same session | **Keep**, indicates user engagement with the service |\n",
    "| `length`    | Numerical     | Number of seconds of the song listened by user | **Keep**, indicates user engagement with the service |\n",
    "| `level`    | Categorical     | Free or paid user? | **Keep**, indicates user engagement with the service. Will be transformed as dummy |\n",
    "| `location`    | Categorical     | User's location (in United States) | **Drop**, it will not help us to identify when user will churn |\n",
    "| `method`    | Categorical     | HTTP method used for the action | **Drop**, it will not help us to identify when user will churn |\n",
    "| `page`    | Categorical     | User's action | **Keep**, needs to be investigated more as it indicates user engagement with the service. Target will be generated from one specific value of this feature |\n",
    "| `registration`    | Numerical     | User's registration timestamp | **Keep**, needs to be investigated more as it indicates user engagement with the service. Target will be generated from one specific value of this feature |\n",
    "| `sessionId`    | Numerical     | Session id | **Keep** to be transformed into something else such as number of times user came back |\n",
    "| `song`    | Categorical     | Song currently played by user | **Drop**, it will not help us to identify when user will churn |\n",
    "| `status`    | Numerical     | HTTP code for user's action | **Drop**, it will not help us to identify when user will churn |\n",
    "| `ts`    | Numerical     | User's action timestamp | **Keep** to be transformed into something else such as number of actions within a time window |\n",
    "| `userAgent`    | Categorical     | User's browser user-agent | **Keep**, maybe we can extract OS and device and dummy that |\n",
    "| `userId`    | Numerical     | User technical id | **Drop**, it will not help us to identify when user will churn |\n",
    "\n",
    "The basic exploration of the dataset is now over and we will now explore in details a clean dataset with the target defined. This will be done in this [notebook about EDA](2_Sparkify_Data_Exploration.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
